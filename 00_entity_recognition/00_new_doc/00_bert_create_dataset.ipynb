<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  value    label\n",
      "0                                 OJC MARKETING SDN BHD  company\n",
      "1                                            15/01/2019     date\n",
      "2     NO 2 & 4, JALAN BAYU 4, BANDAR SERI ALAM, B175...  address\n",
      "3                                                193.00    total\n",
      "4                                 OJC MARKETING SDN BHD  company\n",
      "...                                                 ...      ...\n",
      "1383                                              79.50    total\n",
      "1384                           HON HWA HARDWARE TRADING  company\n",
      "1385                                         21/09/2017     date\n",
      "1386  NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERA...  address\n",
      "1387                                              10.40    total\n",
      "\n",
      "[1388 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assumez que 'dossier' contient la liste des noms de fichiers à traiter\n",
    "dossier = os.listdir(\"../../data/SROIE2019-20231205T160735Z-001/SROIE2019/test/entities/\")\n",
    "# Initialisez une liste pour stocker les données du DataFrame\n",
    "data = []\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier\n",
    "for files in dossier:\n",
    "    # Construire le chemin complet du fichier\n",
    "    filepath = os.path.join('../../data/SROIE2019-20231205T160735Z-001/SROIE2019/test/entities/', files)\n",
    "\n",
    "    # Ouvrir le fichier JSON et le charger\n",
    "    with open(filepath, \"r\", encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        # Ajouter les paires clé-valeur au tableau de données\n",
    "        for key, value in json_data.items():\n",
    "            data.append({'label': key, 'value': value})\n",
    "\n",
    "# Créer un DataFrame à partir des données\n",
    "test_df = pd.DataFrame(data)\n",
    "test_df=test_df[test_df.columns[::-1]]\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  value    label\n",
      "0                       BOOK TA .K (TAMAN DAYA) SDN BHD  company\n",
      "1                                            25/12/2018     date\n",
      "2     NO.53 55,57 & 59, JALAN SAGU 18, TAMAN DAYA, 8...  address\n",
      "3                                                  9.00    total\n",
      "4                                INDAH GIFT & HOME DECO  company\n",
      "...                                                 ...      ...\n",
      "2498                                             102.00    total\n",
      "2499                       LIAN HING STATIONERY SDN BHD  company\n",
      "2500                                         27/03/2018     date\n",
      "2501  NO.32 & 33, JALAN SR 1/9, SEKSYEN 9, TAMAN SER...  address\n",
      "2502                                              12.00    total\n",
      "\n",
      "[2503 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assumez que 'dossier' contient la liste des noms de fichiers à traiter\n",
    "dossier = os.listdir(\"../../data/SROIE2019-20231205T160735Z-001/SROIE2019/train/entities/\")\n",
    "# Initialisez une liste pour stocker les données du DataFrame\n",
    "data = []\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier\n",
    "for files in dossier:\n",
    "    # Construire le chemin complet du fichier\n",
    "    filepath = os.path.join('../../data/SROIE2019-20231205T160735Z-001/SROIE2019/train/entities/', files)\n",
    "\n",
    "    # Ouvrir le fichier JSON et le charger\n",
    "    with open(filepath, \"r\", encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        # Ajouter les paires clé-valeur au tableau de données\n",
    "        for key, value in json_data.items():\n",
    "            data.append({'label': key, 'value': value})\n",
    "\n",
    "# Créer un DataFrame à partir des données\n",
    "train_df = pd.DataFrame(data)\n",
    "train_df=train_df[train_df.columns[::-1]]\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e077926/miniconda3/Bib/envs/tata_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Créer le DatasetDict\n",
    "from datasets import DatasetDict, Dataset \n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_dict(train_df),\n",
    "    'test': Dataset.from_dict(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address', 'company', 'date', 'total']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = dataset_dict['train'].unique('label')\n",
    "label_list.sort()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOOK TA .K (TAMAN DAYA) SDN BHD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['train'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['value', 'label'],\n",
       "        num_rows: 2503\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['value', 'label'],\n",
       "        num_rows: 1388\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder mon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2503/2503 [00:00<00:00, 139026.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1388/1388 [00:00<00:00, 75002.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.save_to_disk('../../data/sroie_dataset.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  value    label\n",
      "0                                 OJC MARKETING SDN BHD  company\n",
      "1                                            15/01/2019     date\n",
      "2     NO 2 & 4, JALAN BAYU 4, BANDAR SERI ALAM, B175...  address\n",
      "3                                                193.00    total\n",
      "4                                 OJC MARKETING SDN BHD  company\n",
      "...                                                 ...      ...\n",
      "1383                                              79.50    total\n",
      "1384                           HON HWA HARDWARE TRADING  company\n",
      "1385                                         21/09/2017     date\n",
      "1386  NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERA...  address\n",
      "1387                                              10.40    total\n",
      "\n",
      "[1388 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assumez que 'dossier' contient la liste des noms de fichiers à traiter\n",
    "dossier = os.listdir(\"../../data/SROIE2019-20231205T160735Z-001/SROIE2019/test/entities/\")\n",
    "# Initialisez une liste pour stocker les données du DataFrame\n",
    "data = []\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier\n",
    "for files in dossier:\n",
    "    # Construire le chemin complet du fichier\n",
    "    filepath = os.path.join('../../data/SROIE2019-20231205T160735Z-001/SROIE2019/test/entities/', files)\n",
    "\n",
    "    # Ouvrir le fichier JSON et le charger\n",
    "    with open(filepath, \"r\", encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        # Ajouter les paires clé-valeur au tableau de données\n",
    "        for key, value in json_data.items():\n",
    "            data.append({'label': key, 'value': value})\n",
    "\n",
    "# Créer un DataFrame à partir des données\n",
    "test_df = pd.DataFrame(data)\n",
    "test_df=test_df[test_df.columns[::-1]]\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  value    label\n",
      "0                       BOOK TA .K (TAMAN DAYA) SDN BHD  company\n",
      "1                                            25/12/2018     date\n",
      "2     NO.53 55,57 & 59, JALAN SAGU 18, TAMAN DAYA, 8...  address\n",
      "3                                                  9.00    total\n",
      "4                                INDAH GIFT & HOME DECO  company\n",
      "...                                                 ...      ...\n",
      "2498                                             102.00    total\n",
      "2499                       LIAN HING STATIONERY SDN BHD  company\n",
      "2500                                         27/03/2018     date\n",
      "2501  NO.32 & 33, JALAN SR 1/9, SEKSYEN 9, TAMAN SER...  address\n",
      "2502                                              12.00    total\n",
      "\n",
      "[2503 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assumez que 'dossier' contient la liste des noms de fichiers à traiter\n",
    "dossier = os.listdir(\"../../data/SROIE2019-20231205T160735Z-001/SROIE2019/train/entities/\")\n",
    "# Initialisez une liste pour stocker les données du DataFrame\n",
    "data = []\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier\n",
    "for files in dossier:\n",
    "    # Construire le chemin complet du fichier\n",
    "    filepath = os.path.join('../../data/SROIE2019-20231205T160735Z-001/SROIE2019/train/entities/', files)\n",
    "\n",
    "    # Ouvrir le fichier JSON et le charger\n",
    "    with open(filepath, \"r\", encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        # Ajouter les paires clé-valeur au tableau de données\n",
    "        for key, value in json_data.items():\n",
    "            data.append({'label': key, 'value': value})\n",
    "\n",
    "# Créer un DataFrame à partir des données\n",
    "train_df = pd.DataFrame(data)\n",
    "train_df=train_df[train_df.columns[::-1]]\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e077926/miniconda3/Bib/envs/tata_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Créer le DatasetDict\n",
    "from datasets import DatasetDict, Dataset \n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_dict(train_df),\n",
    "    'test': Dataset.from_dict(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address', 'company', 'date', 'total']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = dataset_dict['train'].unique('label')\n",
    "label_list.sort()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOOK TA .K (TAMAN DAYA) SDN BHD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['train'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['value', 'label'],\n",
       "        num_rows: 2503\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['value', 'label'],\n",
       "        num_rows: 1388\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder mon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2503/2503 [00:00<00:00, 139026.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1388/1388 [00:00<00:00, 75002.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.save_to_disk('../../data/sroie_dataset.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> 0f64690af03ca4633cc152e3237766b7451a88fc
